#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë°ì´í„° ì¶”ì¶œ ë° ì²˜ë¦¬ ê´€ë ¨ í•¨ìˆ˜ë“¤
"""

import hashlib
import difflib
import re
import requests
from bs4 import BeautifulSoup
from datetime import datetime, date
from fetchers import log, remove_unwanted_elements

# format_attendance_infoì—ì„œ ì‚¬ìš©í•˜ëŠ” API ì„¤ì •
CAFE24_API_URL = 'https://rofan.mycafe24.com/tracker/api/external_api.php'
API_TOKEN = 'rofan-tracker-token-2025-secure-key'

headers = {
    'Authorization': f'Bearer {API_TOKEN}',
    'Content-Type': 'application/json'
}

def generate_hash(content):
    """ì»¨í…ì¸  í•´ì‹œ ìƒì„±"""
    return hashlib.sha256(content.encode('utf-8')).hexdigest()

def generate_diff(old_text, new_text):
    """ê°„ë‹¨í•œ diff HTML ìƒì„±"""
    old_words = old_text.split()
    new_words = new_text.split()
    
    diff = difflib.SequenceMatcher(None, old_words, new_words)
    html_parts = []
    
    for opcode, i1, i2, j1, j2 in diff.get_opcodes():
        if opcode == 'equal':
            html_parts.append(' '.join(old_words[i1:i2]))
        elif opcode == 'delete':
            for word in old_words[i1:i2]:
                html_parts.append(f'<span class="diff-removed" style="background-color: #f8d7da; color: #721c24; text-decoration: line-through;">{word}</span>')
        elif opcode == 'insert':
            for word in new_words[j1:j2]:
                html_parts.append(f'<span class="diff-added" style="background-color: #d4edda; color: #155724; font-weight: bold;">{word}</span>')
        elif opcode == 'replace':
            for word in old_words[i1:i2]:
                html_parts.append(f'<span class="diff-removed" style="background-color: #f8d7da; color: #721c24; text-decoration: line-through;">{word}</span>')
            for word in new_words[j1:j2]:
                html_parts.append(f'<span class="diff-added" style="background-color: #d4edda; color: #155724; font-weight: bold;">{word}</span>')
    
    return '<div class="diff-content">' + ' '.join(html_parts) + '</div>'

def format_attendance_info(site_id, site_name, current_attendance_records, detected_time_str):
    """ì¶œê·¼ë¶€ ì •ë³´ë¥¼ í¬ë§·íŒ…í•˜ì—¬ HTML ìƒì„±"""
    try:
        today = date.today().isoformat()
        
        # ìµœì´ˆ ì¶œê·¼ ì¸ì› ê°€ì ¸ì˜¤ê¸° (API í˜¸ì¶œ)
        try:
            response = requests.get(f'{CAFE24_API_URL}?action=get_first_attendance', 
                                  params={'site_id': site_id, 'attendance_date': today},
                                  headers=headers, timeout=10)
            if response.status_code == 200:
                result = response.json()
                if result.get('success') and result.get('data'):
                    first_attendance = result['data']
                else:
                    first_attendance = []
            else:
                first_attendance = []
        except:
            first_attendance = []
        
        # í˜„ì¬ ì¶œê·¼ ì¸ì›ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        current_dict = {}
        for record in current_attendance_records:
            name = record['name']
            times_str = record['times']
            times_set = set(times_str.split(',')) if times_str else set()
            current_dict[name] = times_set
        
        # ìµœì´ˆ ì¶œê·¼ ì¸ì›ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        first_dict = {}
        for record in first_attendance:
            name = record.get('staff_name', '')
            times_str = record.get('work_times', '')
            times_set = set(times_str.split(',')) if times_str else set()
            if name:
                first_dict[name] = times_set
        
        # ìµœì´ˆ ì¶œê·¼ ì¸ì›ì´ ì—†ìœ¼ë©´ í˜„ì¬ ì¶œê·¼ ì¸ì›ì„ ìµœì´ˆë¡œ ì„¤ì •
        if not first_dict and current_dict:
            first_dict = {name: times.copy() for name, times in current_dict.items()}
        
        # HTML ìƒì„±
        html_parts = []
        
        # ë‚ ì§œ ì¶”ì¶œ (YYYY-MM-DD í˜•ì‹)
        try:
            year, month, day = today.split('-')
            date_str = f"{int(month)}ì›”{int(day)}ì¼"
        except:
            date_str = today
        
        html_parts.append(
            f'<div class="attendance-summary-block" data-site-id="{site_id}" '
            f'data-detected-time="{detected_time_str}" '
            f'style="margin: 15px 0; padding: 15px; background-color: #f8f9fa; border-radius: 5px;">'
        )
        html_parts.append(f'<h6 style="margin-bottom: 10px; font-weight: bold;">{site_name} {date_str} {detected_time_str}</h6>')
        
        # ìµœì´ˆ ì¶œê·¼ ì¸ì› í‘œì‹œ
        if first_dict:
            first_list = []
            for name in sorted(first_dict.keys()):
                times_list = sorted([int(t) for t in first_dict[name] if t.isdigit()])
                times_str = ','.join(map(str, times_list))
                first_list.append(f"{name} {times_str}")
            html_parts.append(
                '<div class="attendance-line" data-kind="initial" style="margin-bottom: 8px;">'
                '<span class="attendance-label">[ìµœì´ˆì¶œê·¼ì¸ì›]</span>'
                '<span class="attendance-sep"> : </span>'
                f'<span class="attendance-value">{" / ".join(first_list)}</span>'
                '</div>'
            )
        
        # í˜„ì¬ ì˜ˆì•½ ê°€ëŠ¥ ì¸ì› í‘œì‹œ
        if current_dict:
            current_list = []
            for name in sorted(current_dict.keys()):
                times_list = sorted([int(t) for t in current_dict[name] if t.isdigit()])
                # ìµœì´ˆ ì¶œê·¼ ì¸ì›ê³¼ ë¹„êµí•˜ì—¬ ì˜ˆì•½ ë¶ˆê°€ëŠ¥í•œ ì‹œê°„ì— <u> íƒœê·¸ ì ìš©
                if name in first_dict:
                    first_times = first_dict[name]
                    formatted_times = []
                    for time_val in times_list:
                        time_str = str(time_val)
                        if time_str not in first_times:
                            formatted_times.append(f'<u>{time_str}</u>')
                        else:
                            formatted_times.append(time_str)
                    times_display = ','.join(formatted_times)
                else:
                    times_display = ','.join(map(str, times_list))
                current_list.append(f"{name} {times_display}")
            html_parts.append(
                f'<div class="attendance-line" data-kind="current" data-time="{detected_time_str}" style="margin-bottom: 6px;">'
                f'<span class="attendance-label">[{detected_time_str} ì˜ˆì•½ê°€ëŠ¥ì¸ì›]</span>'
                '<span class="attendance-sep"> : </span>'
                f'<span class="attendance-value">{" / ".join(current_list)}</span>'
                '</div>'
            )
        
        html_parts.append('</div>')
        
        return ''.join(html_parts)
    except Exception as e:
        log(f"  âœ— Error formatting attendance info: {str(e)}")
        import traceback
        log(f"  Traceback: {traceback.format_exc()}")
        return ""

def extract_attendance_data(content_text, html_content, extraction_mode='both'):
    """ì¶œê·¼ë¶€ ë°ì´í„° ì¶”ì¶œ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›, v6, í•„í„°ë§ ê°•í™”, ì¤‘ë³µ ì œê±°)"""
    attendance_records = []
    processed_records = set()
    name_to_times = {}  # ì´ë¦„ë³„ë¡œ ì‹œê°„ì„ í†µí•©í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    log(f"  DEBUG (extract_attendance_data): Starting extraction v6, mode: {extraction_mode}")

    try:
        # ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ëª©ë¡ (ì¶œê·¼ë¶€ê°€ ì•„ë‹Œ ì¼ë°˜ ì •ë³´) - ê°•í™”
        excluded_keywords = {
            'document', 'ê³ ë§™', 'ì²«', 'ë‚´ìƒzero', 'ë‚´ìƒë¥ ', 'ì˜ì—…', 'ì´ë²¤íŠ¸ì¤‘', 
            'ì£¼ëŒ€', 'ì§‘', 'ì¹´í†¡', 'ì¶œê·¼ë¶€', 'ì‚¬ì¥', 'ì‹¤ì¥', 'ëŒ€í‘œ', 'êµëŒ€',
            'ë‚˜ì´ì•„ê°€ë¼', 'ë¶€ì²œëœë“œë§ˆí¬', 'ë¶ì°½ë™', 'ë„íŒŒë¯¼', 'ë¹ ë‚˜ë‚˜', 'ì—¬ì‚¬ì¹œ',
            'ì¸ìŠ¤íƒ€', 'ì´ì •ì¬', 'í•˜ë‹ˆ', 'í™€ë”±ë²—ì€', 'ë‚˜ë§Œë§›ë³´ëŠ”', 'ëŒ€100ëª…',
            'ì²­ê²°ë§¤ì¥', 'ì›Œí„°ë°¤íœ´ê²Œ', 'ì˜¬íƒˆí•˜ë“œ', 'ìƒë™', 'dior', 'ê¶Œì§€ìš©',
            'ìƒë™í‚¤ìŠ¤ê³ ', 'í‚¤ìŠ¤ê³ ', 'nfëŒ€ê±°ì˜ì…', 'ëŒ€ê±°ì˜ì…', 'ê°•ë‚¨', 'ì „ì›',
            'ì¶œë™', 'í…”ë˜ê·¸ë¨', 'í›„ë¶ˆì œ', 'new', 'ìˆœìˆ˜ì—…ê³„', 'ë°°ìš°ì—°ìŠµìƒ',
            'ëŒ€í•™ìƒ', 'í•˜ìœ ì§„', 'ì˜¬ë¼ê°€ë©´', 'ê³ ì •11', 'hero', 'ë¶€ì²œ', 'íˆì–´ë¡œ',
            'ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼'
        }
        
        # ë¶ˆí•„ìš”í•œ ì´ë¦„ íŒ¨í„´
        excluded_name_patterns = [
            r'.*ì‚¬ì¥$', r'.*ì‹¤ì¥$', r'.*ëŒ€í‘œ$', r'.*ì¶œê·¼ë¶€$', r'.*ì¹´í†¡$',
            r'^Document', r'^ê³ ë§™', r'^ì²«\d+', r'^ë‚´ìƒ', r'^ì˜ì—…', r'^ì´ë²¤íŠ¸',
            r'^ì£¼ëŒ€$', r'^ì§‘$', r'^ì¶œê·¼ë¶€$', r'^ì¹´í†¡$', r'^êµëŒ€$',
            r'^NFëŒ€ê±°ì˜ì…$', r'^ëŒ€ê±°ì˜ì…$', r'^ê°•ë‚¨$', r'^ì „ì›$', r'^ì¶œë™$',
            r'^í…”ë˜ê·¸ë¨$', r'^í›„ë¶ˆì œ$', r'^new$', r'^ìˆœìˆ˜ì—…ê³„$', r'^ë°°ìš°ì—°ìŠµìƒ$',
            r'^ëŒ€í•™ìƒ$', r'^í•˜ìœ ì§„$', r'^ì˜¬ë¼ê°€ë©´$', r'^ê³ ì •\d+$',
            r'^\d+ì›”\d+ì¼$', r'^[ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼]ìš”ì¼$', r'^ì›”\d+ì¼$', r'^\d+ì¼$'
        ]

        def parse_times_from_string(time_str_raw):
            """ì…ë ¥ ë¬¸ìì—´ì—ì„œ ì‹œê°„ì„ íŒŒì‹±í•˜ì—¬ ì •ê·œí™”ëœ ì‰¼í‘œ êµ¬ë¶„ ë¬¸ìì—´ë¡œ ë°˜í™˜ (0-24 ë²”ìœ„ë§Œ í—ˆìš©)"""
            time_str = re.sub(r'[ì‹œë¶„ì´ˆ]', '', time_str_raw)
            numbers = [int(n) for n in re.findall(r'\d+', time_str)]
            if not numbers:
                return None

            if any(n >= 25 for n in numbers):
                return None

            if '~' in time_str and len(numbers) >= 2:
                start, end = numbers[0], numbers[-1]
                if start >= 25 or end >= 25:
                    return None
                
                times = []
                if start == 24:
                    times.append(24)
                    if end < 24:
                        times.extend(range(1, end))
                elif start > end:
                    times.extend(range(start, 24))
                    if end < 24:
                        times.extend(range(0, end))
                else:
                    times.extend(range(start, end))
                
                times = [t for t in times if 0 <= t <= 24]
                if not times:
                    return None
                
                return ','.join(map(str, sorted(list(set(times)))))
            else:
                valid_times = [n for n in numbers if 0 <= n <= 24]
                if not valid_times:
                    return None
                return ','.join(map(str, sorted(list(set(valid_times)))))

        def is_excluded_name(name):
            """ì´ë¦„ì´ ì œì™¸ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸"""
            name_lower = name.lower()
            for keyword in excluded_keywords:
                if keyword in name_lower:
                    return True
            for pattern in excluded_name_patterns:
                if re.match(pattern, name, re.IGNORECASE):
                    return True
            return False

        def normalize_name(name):
            """ì´ë¦„ ì •ê·œí™”: NF, ACE ë“±ì˜ ì ‘ë‘ì‚¬ ì œê±°í•˜ê³  ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œ"""
            if 'ë‹¤ìœ¨' in name or 'Queen' in name or 'í€¸' in name:
                return 'ë‹¤ìœ¨'
            name_clean = re.sub(r'^(NF|ACE|NEW|new)\s*', '', name, flags=re.IGNORECASE)
            name_clean = re.sub(r'^(Queen|í€¸)\s*', '', name_clean, flags=re.IGNORECASE)
            return name_clean.strip()
        
        # ì œëª©ê³¼ ë³¸ë¬¸ ë¶„ë¦¬
        title_text = ""
        body_text = ""
        
        if content_text:
            title_match = re.search(r'\[ì œëª©\]\s*(.*?)(?=\[ë³¸ë¬¸\]|$)', content_text, re.DOTALL)
            body_match = re.search(r'\[ë³¸ë¬¸\]\s*(.*?)$', content_text, re.DOTALL)
            
            if title_match:
                title_text = title_match.group(1).strip()
            if body_match:
                body_text = body_match.group(1).strip()
            
            if not title_text and not body_text:
                body_text = content_text
        
        soup = None
        html_full_text = ""
        if html_content:
            soup = BeautifulSoup(html_content, 'lxml')
            remove_unwanted_elements(soup)
            html_full_text = soup.get_text(separator=' ', strip=True)
        
        def clean_text(raw_text):
            if not raw_text:
                return ""
            text = raw_text
            text = re.sub(r'\d+ì›”\s*\d+ì¼', ' ', text)
            text = re.sub(r'\(\d+\.\d+\)', ' ', text)
            text = re.sub(r'\([^)]*\)', ' ', text)
            text = re.sub(r'\d+/\d+/\d+/[A-Za-zê°€-í£]+/[ê°€-í£]+', ' ', text)
            text = re.sub(r'\d+/\d+/\d+/[A-Za-zê°€-í£]+', ' ', text)
            text = re.sub(r'\d+/\d+/\d+', ' ', text)
            text = re.sub(r'[â¤ï¸âœ…â­ï¸ğŸ€ğŸ’›ğŸ’™ğŸ’œğŸ’šğŸ§¡ğŸ–¤ğŸ¤ğŸ¤âœ¨]', ' ', text)
            text = re.sub(r'[\[\]]', ' ', text)
            return text
        
        texts_to_parse = []
        if extraction_mode in ('both', 'body'):
            if body_text:
                texts_to_parse.append(('body', body_text))
            elif html_full_text:
                texts_to_parse.append(('body', html_full_text))
        if extraction_mode in ('both', 'title'):
            if title_text:
                texts_to_parse.append(('title', title_text))
            elif soup:
                title_elem = soup.find('title') or soup.find('h1')
                if title_elem:
                    texts_to_parse.append(('title', title_elem.get_text(strip=True)))
        if not texts_to_parse:
            fallback = content_text or html_full_text or ""
            texts_to_parse.append(('fallback', fallback))
        
        name_pattern = r'[a-zA-Zê°€-í£][a-zA-Z0-9ê°€-í£]*'
        pattern = re.compile(f'({name_pattern})\\s+(.*?)(?=\\s+{name_pattern}|$)')
        
        for source, raw_text in texts_to_parse:
            cleaned_text = clean_text(raw_text)
            if not cleaned_text:
                continue
            matches = pattern.finditer(cleaned_text)

            for match in matches:
                name = match.group(1).strip()
                raw_time_part = match.group(2).strip()

                if len(name) == 1 and name in "ì‹œë¶„ì´ˆì›”ì¼":
                    continue
                
                if is_excluded_name(name):
                    log(f"  DEBUG (extract_attendance_data): Excluded name: {name}")
                    continue
                
                if re.search(r'\d+/\d+/\d+', raw_time_part):
                    log(f"  DEBUG (extract_attendance_data): Excluded time part (contains age/height/weight): {raw_time_part}")
                    continue
                
                if not any(char.isdigit() for char in raw_time_part):
                    continue

                parsed_times = parse_times_from_string(raw_time_part)
                
                if parsed_times:
                    normalized_name = normalize_name(name)
                    
                    if normalized_name in name_to_times:
                        existing_times = set(name_to_times[normalized_name].split(','))
                        new_times = set(parsed_times.split(','))
                        combined_times = sorted(list(existing_times | new_times))
                        name_to_times[normalized_name] = ','.join(combined_times)
                        log(f"  DEBUG (extract_attendance_data): Merged times for {normalized_name}: {name_to_times[normalized_name]}")
                    else:
                        name_to_times[normalized_name] = parsed_times
                        log(f"  DEBUG (extract_attendance_data): Added record: {normalized_name}, {parsed_times}")
        
        # name_to_timesë¥¼ attendance_recordsë¡œ ë³€í™˜
        for name, times in name_to_times.items():
            attendance_records.append({
                'name': name,
                'times': times,
                'raw': f"{name} {times}"
            })

    except Exception as e:
        log(f"âœ—âœ—âœ— ERROR in extract_attendance_data: {str(e)} âœ—âœ—âœ—")
        import traceback
        log(f"  Traceback: {traceback.format_exc()}")

    log(f"  DEBUG (extract_attendance_data): Final attendance records count: {len(attendance_records)}")
    return attendance_records

def extract_phone_numbers(html_content):
    """ì „í™”ë²ˆí˜¸ ì¶”ì¶œ (êµ¬ì¡°ì  ê²€ìƒ‰ -> í…ìŠ¤íŠ¸ ê²€ìƒ‰ -> ì •ê·œì‹ ê²€ìƒ‰ ìˆœ)"""
    phone_numbers = []
    
    if not html_content:
        log(f"  DEBUG (extract_phone_numbers): No HTML content provided")
        return phone_numbers
    
    log(f"  DEBUG (extract_phone_numbers): HTML content length: {len(html_content)} characters")
    
    soup = BeautifulSoup(html_content, 'lxml')
    remove_unwanted_elements(soup)
    
    for script in soup(["script", "style"]):
        script.extract()
    
    def normalize_phone(phone_str):
        """ì „í™”ë²ˆí˜¸ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™” (010-1234-5678)"""
        if not phone_str:
            return None
        phone_str = phone_str.replace('.', '-').replace(' ', '-')
        digits = re.sub(r'\D', '', phone_str)
        
        if len(digits) < 9 or len(digits) > 11 or not digits.startswith('0'):
            return None
            
        if len(digits) == 11:
            return f"{digits[:3]}-{digits[3:7]}-{digits[7:]}"
        elif len(digits) == 10:
            if digits.startswith('02'):
                return f"{digits[:2]}-{digits[2:6]}-{digits[6:]}"
            else:
                return f"{digits[:3]}-{digits[3:6]}-{digits[6:]}"
        elif len(digits) == 9:
            if digits.startswith('02'):
                return f"{digits[:2]}-{digits[2:5]}-{digits[5:]}"
            else:
                return f"{digits[:3]}-{digits[3:6]}-{digits[6:]}"
        return None

    def is_valid_phone(phone):
        return re.match(r'^0(1[016789]|2|[3-6][1-9]|70)-\d{3,4}-\d{4}$', phone)

    # ì „ëµ 0: table.et_vars ìš°ì„  ê²€ìƒ‰
    for table in soup.select('table.et_vars, table.vars, table.info'):
        has_phone_label = False
        for th in table.select('th'):
            if 'ì „í™”' in th.get_text():
                has_phone_label = True
                break
        
        if has_phone_label:
            text = table.get_text(separator=' ', strip=True)
            matches = re.findall(r'0\d{1,2}[-.\s]?\d{3,4}[-.\s]?\d{4}', text)
            for raw in matches:
                norm = normalize_phone(raw)
                if norm and is_valid_phone(norm) and norm not in phone_numbers:
                    phone_numbers.append(norm)
                    log(f"  DEBUG (extract_phone_numbers): Found phone in table.et_vars (global search): {norm}")
    
    if phone_numbers:
        return phone_numbers

    # 2. í´ë˜ìŠ¤ê°€ ì—†ì§€ë§Œ 'ì „í™”ë²ˆí˜¸'ê°€ í¬í•¨ëœ ëª¨ë“  í…Œì´ë¸” ê²€ìƒ‰
    for table in soup.find_all('table'):
        has_phone_label = False
        for cell in table.find_all(['th', 'td']):
            if 'ì „í™”' in cell.get_text():
                has_phone_label = True
                break
        
        if has_phone_label:
            text = table.get_text(separator=' ', strip=True)
            matches = re.findall(r'0\d{1,2}[-.\s]?\d{3,4}[-.\s]?\d{4}', text)
            for raw in matches:
                norm = normalize_phone(raw)
                if norm and is_valid_phone(norm) and norm not in phone_numbers:
                    phone_numbers.append(norm)
                    log(f"  DEBUG (extract_phone_numbers): Found phone in general table (global search): {norm}")

    if phone_numbers:
        return phone_numbers

    # Scope Definition
    scope_element = None
    scope_element = soup.select_one('[data-docsrl]')
    if scope_element:
        log(f"  DEBUG (extract_phone_numbers): Scope restricted to [data-docsrl]")
    
    if not scope_element:
        scope_element = soup.select_one('.rd_body')
        if scope_element:
            log(f"  DEBUG (extract_phone_numbers): Scope restricted to .rd_body")
            
    if not scope_element:
        scope_element = soup.select_one('.xe_content')
        if scope_element:
            log(f"  DEBUG (extract_phone_numbers): Scope restricted to .xe_content")
    
    if not scope_element:
        scope_element = soup.find('article')
        if scope_element:
            log(f"  DEBUG (extract_phone_numbers): Scope restricted to article")

    if not scope_element:
        log(f"  DEBUG (extract_phone_numbers): No specific scope found, searching entire document (cleaned)")
        scope_element = soup

    # ì „ëµ 1: ëª…ì‹œì ì¸ 'ì „í™”ë²ˆí˜¸' ë ˆì´ë¸” ì£¼ë³€ ê²€ìƒ‰
    labels = scope_element.find_all(string=re.compile(r'(ì „í™”|ì—°ë½)'))
    for label in labels:
        parent = label.parent
        if parent is None:
            continue
            
        text = parent.get_text(separator=' ', strip=True)
        matches = re.findall(r'0\d{1,2}[-.\s]?\d{3,4}[-.\s]?\d{4}', text)
        for raw in matches:
            norm = normalize_phone(raw)
            if norm and is_valid_phone(norm) and norm not in phone_numbers:
                phone_numbers.append(norm)
                log(f"  DEBUG (extract_phone_numbers): Found phone near label '{label.strip()}' (same tag): {norm}")

        next_elem = parent.find_next_sibling()
        if next_elem:
            text = next_elem.get_text(separator=' ', strip=True)
            matches = re.findall(r'0\d{1,2}[-.\s]?\d{3,4}[-.\s]?\d{4}', text)
            for raw in matches:
                norm = normalize_phone(raw)
                if norm and is_valid_phone(norm) and norm not in phone_numbers:
                    phone_numbers.append(norm)
                    log(f"  DEBUG (extract_phone_numbers): Found phone near label '{label.strip()}' (next sibling): {norm}")
        
        tr = parent.find_parent('tr')
        if tr:
            cells = tr.find_all(['th', 'td'])
            for i, cell in enumerate(cells):
                if cell == parent or parent in cell.descendants:
                    if i + 1 < len(cells):
                        next_cell = cells[i+1]
                        text = next_cell.get_text(separator=' ', strip=True)
                        matches = re.findall(r'0\d{1,2}[-.\s]?\d{3,4}[-.\s]?\d{4}', text)
                        for raw in matches:
                            norm = normalize_phone(raw)
                            if norm and is_valid_phone(norm) and norm not in phone_numbers:
                                phone_numbers.append(norm)
                                log(f"  DEBUG (extract_phone_numbers): Found phone in table row next cell: {norm}")

    if phone_numbers:
        return phone_numbers

    # ì „ëµ 2: Scope ë‚´ í…ìŠ¤íŠ¸ì—ì„œ ì •ê·œì‹ ê²€ìƒ‰
    scope_text = scope_element.get_text(separator=' ', strip=True)
    
    matches = re.findall(r'010[-.\s]?\d{4}[-.\s]?\d{4}', scope_text)
    for raw in matches:
        norm = normalize_phone(raw)
        if norm and is_valid_phone(norm) and norm not in phone_numbers:
            phone_numbers.append(norm)
            log(f"  DEBUG (extract_phone_numbers): Found 010 phone in scope text: {norm}")
            
    if not phone_numbers:
        matches = re.findall(r'0\d{1,2}[-.\s]?\d{3,4}[-.\s]?\d{4}', scope_text)
        for raw in matches:
            norm = normalize_phone(raw)
            if norm and is_valid_phone(norm) and norm not in phone_numbers:
                phone_numbers.append(norm)
                log(f"  DEBUG (extract_phone_numbers): Found general phone in scope text: {norm}")

    if not phone_numbers:
        log(f"  DEBUG (extract_phone_numbers): No phone numbers found in scope")

    return phone_numbers





